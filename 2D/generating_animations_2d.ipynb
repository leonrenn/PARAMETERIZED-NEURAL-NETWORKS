{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Animations\n",
    "--- \n",
    "Animation of two gaussians in 2D with one depicting the background and the other one being the signal. <br>\n",
    "The probability to discard the background hypothesis is dependent on the position of the signal peak in reference to the background.<br>\n",
    "One animation shows the case that the signals mean is varied in a grid wise procedure while the background is kept at the same place.<br>\n",
    "The other animation shows the signal rotating around the background. In the regions where the network was no trained explicitly the values for discarding the background hypothesis cannot be seen as reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extern modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "\n",
    "# intern modules\n",
    "from PNN_model_2d import ParameterizedNeuralNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to file\n",
    "PATH: str = \"../trained_models/PNN_2d.pth\"\n",
    "\n",
    "# load model from \n",
    "model = ParameterizedNeuralNet()\n",
    "PNN_state_dict = torch.load(PATH)\n",
    "model.load_state_dict(PNN_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Multiple Frames and Save in Dedicated Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the coordinate system\n",
    "x_data = np.linspace(-2, 2, 100)\n",
    "y_data = np.linspace(-2, 2, 100)\n",
    "coordinates = np.array([[x, y] for x in x_data for y in y_data])\n",
    "\n",
    "# choosing the background to be at [0.5,0.5]\n",
    "bg_mean = [0.5, 0.5]\n",
    "background = np.multiply(np.ones_like(coordinates), np.array(bg_mean))\n",
    "data = np.zeros((100**2, 6))\n",
    "\n",
    "# covariance\n",
    "cov = np.eye(2) * 0.02\n",
    "\n",
    "# sizes\n",
    "sizes = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Grid Animation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range for scanning through NN\n",
    "animation_range = np.linspace(0, 1, 10)\n",
    "\n",
    "# generating the grid for the scanned region\n",
    "signals = np.array([[x, y] for x in animation_range for y in animation_range])\n",
    "\n",
    "# iterating through the NN\n",
    "for signal_idx, signal in enumerate(signals):\n",
    "\n",
    "    # creation data vector for the PNN\n",
    "    data[:, 0:2] = coordinates\n",
    "    data[:, 2:4] = background\n",
    "    data[:, 4:6] = np.multiply(np.ones_like(coordinates), np.array(signal))\n",
    "\n",
    "    # model evaluation\n",
    "    res = model(torch.Tensor(data)).detach().numpy()\n",
    "\n",
    "    # plot the heatmap for the whole coordinate grid\n",
    "    plt.scatter(coordinates[:,0],coordinates[:,1], marker = '.', facecolor = 'none', edgecolor = plt.get_cmap('viridis')(res))\n",
    "\n",
    "    # generate examples of the hypothesis\n",
    "    example = [np.random.multivariate_normal(bg_mean, cov, size=sizes), np.random.multivariate_normal(signal, cov, size=sizes)]\n",
    "\n",
    "    # plot examples\n",
    "    plt.scatter(example[0][:,0], example[0][:, 1], marker=\".\", alpha=0.3)\n",
    "    plt.scatter(example[1][:,0], example[1][:, 1], marker=\".\", alpha=0.3)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    # save the plot\n",
    "    plt.savefig((f'../frames/2d_signal_grid_idx_{signal_idx}.png'))\n",
    "\n",
    "    # flush the figure\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Multiple Frames in GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.stack([iio.imread(f'../frames/2d_signal_grid_idx_{signal_idx}.png') for signal_idx, signal in enumerate(signals)], axis=0)\n",
    "iio.imwrite('../animations/2d_signal_grid.gif', frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display GIF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../animations/2d_signal_grid.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Circular Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle for scanning through NN\n",
    "phi = np.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "# generating the grid for the scanned region\n",
    "signals = np.array([[0.5 * np.cos(x) + 0.5, 0.5 * np.sin(x)+ 0.5] for x in phi])\n",
    "\n",
    "# iterating through the NN\n",
    "for signal_idx, signal in enumerate(signals):\n",
    "\n",
    "    # creation data vector for the PNN\n",
    "    data[:, 0:2] = coordinates\n",
    "    data[:, 2:4] = background\n",
    "    data[:, 4:6] = np.multiply(np.ones_like(coordinates), np.array(signal))\n",
    "\n",
    "    # model evaluation\n",
    "    res = model(torch.Tensor(data)).detach().numpy()\n",
    "\n",
    "    # plot the heatmap for the whole coordinate grid\n",
    "    plt.scatter(coordinates[:,0],coordinates[:,1], marker = '.', facecolor = 'none', edgecolor = plt.get_cmap('viridis')(res))\n",
    "\n",
    "    # generate examples of the hypothesis\n",
    "    example = [np.random.multivariate_normal(bg_mean, cov, size=sizes), np.random.multivariate_normal(signal, cov, size=sizes)]\n",
    "\n",
    "    # plot examples\n",
    "    plt.scatter(example[0][:,0], example[0][:, 1], marker=\".\", alpha=0.3)\n",
    "    plt.scatter(example[1][:,0], example[1][:, 1], marker=\".\", alpha=0.3)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    # save the plot\n",
    "    plt.savefig((f'../frames/2d_signal_circular_idx_{signal_idx}.png'))\n",
    "\n",
    "    # flush the figure\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Multiple Frames in GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.stack([iio.imread(f'../frames/2d_signal_circular_idx_{signal_idx}.png') for signal_idx, signal in enumerate(signals)], axis=0)\n",
    "iio.imwrite('../animations/2d_signal_circular.gif', frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display GIF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../animations/2d_signal_circular.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
